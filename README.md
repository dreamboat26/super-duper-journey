# Asynchronous Advantage Actor-Critic (A3C) Method Implementation For Super Mario Bros

## Introduction

Here is my Pytorch project source code for training an agent to play super mario bros. By using Asynchronous Advantage Actor-Critic (A3C) algorithm introduced in the paper **Asynchronous Methods for Deep Reinforcement Learning**.
<p align="center">
  <img src="demo/video_1_1.gif" width="200">
  <img src="demo/video_1_2.gif" width="200">
  <img src="demo/video_1_4.gif" width="200">
  <img src="demo/video_2_1.gif" width="200"><br/>
  <img src="demo/video_2_2.gif" width="200">
  <img src="demo/video_2_3.gif" width="200">
  <img src="demo/video_2_4.gif" width="200">
  <img src="demo/video_3_1.gif" width="200"><br/>
  <img src="demo/video_3_2.gif" width="200">
  <img src="demo/video_3_3.gif" width="200">
  <img src="demo/video_3_4.gif" width="200">
  <img src="demo/video_4_1.gif" width="200"><br/>
  <img src="demo/video_5_1.gif" width="200">
  <img src="demo/video_6_1.gif" width="200">
  <img src="demo/video_6_3.gif" width="200">
  <img src="demo/video_7_1.gif" width="200"><br/>
  <img src="demo/video_7_3.gif" width="200">
  <img src="demo/video_8_2.gif" width="200">
  <img src="demo/video_8_3.gif" width="200"><br/>
  <i>Sample results</i>
</p>

## How to use the code
Two files to carry out the execution
* **Train your model** by running **python train.py**
* **Test your trained model** by running **python test.py**

## Requirements

* **python 3.6**
* **gym**
* **cv2**
* **pytorch** 
* **numpy**
